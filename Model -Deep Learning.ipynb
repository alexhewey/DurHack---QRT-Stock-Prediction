{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import einops\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_original = pd.read_csv(\"Data/x_train.csv\",index_col=\"ID\")\n",
    "x_test_original = pd.read_csv(\"Data/x_test.csv\",index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>INDUSTRY</th>\n",
       "      <th>INDUSTRY_GROUP</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>RET_1</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>VOLUME_2</th>\n",
       "      <th>...</th>\n",
       "      <th>RET_16</th>\n",
       "      <th>VOLUME_16</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_17</th>\n",
       "      <th>RET_18</th>\n",
       "      <th>VOLUME_18</th>\n",
       "      <th>RET_19</th>\n",
       "      <th>VOLUME_19</th>\n",
       "      <th>RET_20</th>\n",
       "      <th>VOLUME_20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418595</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>0.020208</td>\n",
       "      <td>0.146176</td>\n",
       "      <td>0.010059</td>\n",
       "      <td>0.224756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022364</td>\n",
       "      <td>-0.301163</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>-0.416533</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.161792</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>-0.007221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418596</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>-0.251631</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>-0.712515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002062</td>\n",
       "      <td>-0.679724</td>\n",
       "      <td>-0.001544</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.396372</td>\n",
       "      <td>-0.007875</td>\n",
       "      <td>-0.431760</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>-0.574228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418597</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>-0.115845</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>-0.107441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>-0.451590</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>-0.536967</td>\n",
       "      <td>0.009520</td>\n",
       "      <td>-0.368585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022713</td>\n",
       "      <td>-0.002066</td>\n",
       "      <td>-0.207362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418598</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>91</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>-0.090295</td>\n",
       "      <td>-0.013738</td>\n",
       "      <td>0.048465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010984</td>\n",
       "      <td>-0.039714</td>\n",
       "      <td>0.037018</td>\n",
       "      <td>0.665132</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>0.141991</td>\n",
       "      <td>-0.008191</td>\n",
       "      <td>-0.172382</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>-0.353172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418599</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>0.011419</td>\n",
       "      <td>-0.289027</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>-0.262690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>-0.565747</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>-0.506291</td>\n",
       "      <td>-0.026469</td>\n",
       "      <td>-0.280666</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>0.365773</td>\n",
       "      <td>-0.011134</td>\n",
       "      <td>0.933284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617019</th>\n",
       "      <td>222</td>\n",
       "      <td>5707</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>122</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>-0.476830</td>\n",
       "      <td>-0.006419</td>\n",
       "      <td>-0.534137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>-0.515748</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0.361119</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>-0.132224</td>\n",
       "      <td>0.015389</td>\n",
       "      <td>-0.014298</td>\n",
       "      <td>-0.008680</td>\n",
       "      <td>0.128657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617020</th>\n",
       "      <td>222</td>\n",
       "      <td>5710</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.063269</td>\n",
       "      <td>-0.026928</td>\n",
       "      <td>0.532781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007136</td>\n",
       "      <td>-0.203097</td>\n",
       "      <td>0.032965</td>\n",
       "      <td>0.108639</td>\n",
       "      <td>0.013488</td>\n",
       "      <td>-0.458271</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>-0.353293</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>-0.219671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617021</th>\n",
       "      <td>222</td>\n",
       "      <td>5714</td>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>113</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>-0.506350</td>\n",
       "      <td>-0.016363</td>\n",
       "      <td>-0.173802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016931</td>\n",
       "      <td>0.340198</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>1.087437</td>\n",
       "      <td>-0.012910</td>\n",
       "      <td>1.791362</td>\n",
       "      <td>-0.057857</td>\n",
       "      <td>6.330687</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>1.175063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617022</th>\n",
       "      <td>222</td>\n",
       "      <td>5715</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>138</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>-0.530113</td>\n",
       "      <td>-0.014214</td>\n",
       "      <td>-0.272365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019386</td>\n",
       "      <td>2.046782</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.229290</td>\n",
       "      <td>-0.020338</td>\n",
       "      <td>0.061626</td>\n",
       "      <td>0.022176</td>\n",
       "      <td>-0.414312</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>-0.293960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617023</th>\n",
       "      <td>222</td>\n",
       "      <td>5716</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "      <td>-0.008352</td>\n",
       "      <td>-0.506224</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>-0.508414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>-0.002671</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>-0.250345</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>0.408225</td>\n",
       "      <td>0.027816</td>\n",
       "      <td>0.269808</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.291961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198429 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  STOCK  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY     RET_1  \\\n",
       "ID                                                                              \n",
       "418595     2      0        37              12       5            94  0.020208   \n",
       "418596     2      1        15               4       3            37  0.009134   \n",
       "418597     2      4        57              20       8           142  0.005008   \n",
       "418598     2      5        35              12       5            91  0.015370   \n",
       "418599     2      6        57              20       8           142  0.011419   \n",
       "...      ...    ...       ...             ...     ...           ...       ...   \n",
       "617019   222   5707        52              18       7           122  0.010188   \n",
       "617020   222   5710        33              10       4            83 -0.000838   \n",
       "617021   222   5714        49              17       7           113  0.005941   \n",
       "617022   222   5715        56              20       8           138  0.001775   \n",
       "617023   222   5716        50              17       7           114 -0.008352   \n",
       "\n",
       "        VOLUME_1     RET_2  VOLUME_2  ...    RET_16  VOLUME_16    RET_17  \\\n",
       "ID                                    ...                                  \n",
       "418595  0.146176  0.010059  0.224756  ...  0.022364  -0.301163 -0.001035   \n",
       "418596 -0.251631  0.021913 -0.712515  ... -0.002062  -0.679724 -0.001544   \n",
       "418597 -0.115845  0.005914 -0.107441  ...  0.004458  -0.451590  0.011481   \n",
       "418598 -0.090295 -0.013738  0.048465  ... -0.010984  -0.039714  0.037018   \n",
       "418599 -0.289027  0.022807 -0.262690  ...  0.001045  -0.565747  0.004304   \n",
       "...          ...       ...       ...  ...       ...        ...       ...   \n",
       "617019 -0.476830 -0.006419 -0.534137  ... -0.001028  -0.515748  0.019115   \n",
       "617020 -0.063269 -0.026928  0.532781  ... -0.007136  -0.203097  0.032965   \n",
       "617021 -0.506350 -0.016363 -0.173802  ... -0.016931   0.340198  0.002121   \n",
       "617022 -0.530113 -0.014214 -0.272365  ...  0.019386   2.046782  0.023299   \n",
       "617023 -0.506224  0.006073 -0.508414  ... -0.007219  -0.002671  0.009992   \n",
       "\n",
       "        VOLUME_17    RET_18  VOLUME_18    RET_19  VOLUME_19    RET_20  \\\n",
       "ID                                                                      \n",
       "418595  -0.416533 -0.000148  -0.004548 -0.000148  -0.161792  0.016997   \n",
       "418596  -0.408979  0.001546   0.396372 -0.007875  -0.431760  0.001742   \n",
       "418597  -0.536967  0.009520  -0.368585  0.000000   0.022713 -0.002066   \n",
       "418598   0.665132 -0.003097   0.141991 -0.008191  -0.172382  0.005145   \n",
       "418599  -0.506291 -0.026469  -0.280666  0.010743   0.365773 -0.011134   \n",
       "...           ...       ...        ...       ...        ...       ...   \n",
       "617019   0.361119 -0.002090  -0.132224  0.015389  -0.014298 -0.008680   \n",
       "617020   0.108639  0.013488  -0.458271  0.019894  -0.353293  0.013513   \n",
       "617021   1.087437 -0.012910   1.791362 -0.057857   6.330687 -0.000493   \n",
       "617022   0.229290 -0.020338   0.061626  0.022176  -0.414312 -0.000692   \n",
       "617023  -0.250345 -0.007770   0.408225  0.027816   0.269808  0.009172   \n",
       "\n",
       "        VOLUME_20  \n",
       "ID                 \n",
       "418595  -0.007221  \n",
       "418596  -0.574228  \n",
       "418597  -0.207362  \n",
       "418598  -0.353172  \n",
       "418599   0.933284  \n",
       "...           ...  \n",
       "617019   0.128657  \n",
       "617020  -0.219671  \n",
       "617021   1.175063  \n",
       "617022  -0.293960  \n",
       "617023   0.291961  \n",
       "\n",
       "[198429 rows x 46 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE                  0\n",
      "STOCK                 0\n",
      "INDUSTRY              0\n",
      "INDUSTRY_GROUP        0\n",
      "SECTOR                0\n",
      "SUB_INDUSTRY          0\n",
      "RET_1              2359\n",
      "VOLUME_1          65025\n",
      "RET_2              2465\n",
      "VOLUME_2          66386\n",
      "RET_3              2507\n",
      "VOLUME_3          67819\n",
      "RET_4              2544\n",
      "VOLUME_4          70997\n",
      "RET_5              2584\n",
      "VOLUME_5          74693\n",
      "RET_6              2597\n",
      "VOLUME_6          74714\n",
      "RET_7              2585\n",
      "VOLUME_7          73853\n",
      "RET_8              2623\n",
      "VOLUME_8          73898\n",
      "RET_9              2682\n",
      "VOLUME_9          73298\n",
      "RET_10             2692\n",
      "VOLUME_10         73305\n",
      "RET_11             2961\n",
      "VOLUME_11         72025\n",
      "RET_12             3186\n",
      "VOLUME_12         62523\n",
      "RET_13             3360\n",
      "VOLUME_13         59008\n",
      "RET_14             4413\n",
      "VOLUME_14         60929\n",
      "RET_15             4990\n",
      "VOLUME_15         66373\n",
      "RET_16             5280\n",
      "VOLUME_16         67262\n",
      "RET_17             5301\n",
      "VOLUME_17         62314\n",
      "RET_18             5307\n",
      "VOLUME_18         67586\n",
      "RET_19             5313\n",
      "VOLUME_19         67329\n",
      "RET_20             5341\n",
      "VOLUME_20         67857\n",
      "dtype: int64\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_train_original.isnull().sum())\n",
    "\n",
    "for i in range(1,6):\n",
    "    temp = x_train_original[x_train_original.columns[i]].isnull().sum()\n",
    "    print(temp)\n",
    "\n",
    "# Stock 5716\n",
    "# Industry 74\n",
    "# Industry_group 26\n",
    "# Sector 11\n",
    "# Sub_industry 182\n",
    "\n",
    "# feature dimension - 16, 8, 6, 4, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY\n",
      "ID                                                          \n",
      "418595     2        37              12       5            94\n",
      "418596     2        15               4       3            37\n",
      "418597     2        57              20       8           142\n",
      "418598     2        35              12       5            91\n",
      "418599     2        57              20       8           142\n",
      "...      ...       ...             ...     ...           ...\n",
      "617019   222        52              18       7           122\n",
      "617020   222        33              10       4            83\n",
      "617021   222        49              17       7           113\n",
      "617022   222        56              20       8           138\n",
      "617023   222        50              17       7           114\n",
      "\n",
      "[198429 rows x 5 columns]\n",
      "        DATE  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY\n",
      "ID                                                          \n",
      "0          0        18               5       3            44\n",
      "1          0        43              15       6           104\n",
      "2          0        57              20       8           142\n",
      "3          0         1               1       1             2\n",
      "4          0        36              12       5            92\n",
      "...      ...       ...             ...     ...           ...\n",
      "418590   223        32              10       4            77\n",
      "418591   223        35              12       5            91\n",
      "418592   223         2               1       1             5\n",
      "418593   223        33              10       4            83\n",
      "418594   223        26               7       4            60\n",
      "\n",
      "[418595 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train_additional = x_train_original[x_train_original.columns[[0,2,3,4,5]]]\n",
    "x_test_additional = x_test_original[x_test_original.columns[[0,2,3,4,5]]]\n",
    "x_train_additional_np = x_train_additional.to_numpy()\n",
    "x_test_additional_np = x_test_additional.to_numpy()\n",
    "print(x_test_additional)\n",
    "print(x_train_original[x_train_original.columns[[0,2,3,4,5]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>INDUSTRY</th>\n",
       "      <th>INDUSTRY_GROUP</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>RET_1</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>VOLUME_2</th>\n",
       "      <th>...</th>\n",
       "      <th>RET_16</th>\n",
       "      <th>VOLUME_16</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_17</th>\n",
       "      <th>RET_18</th>\n",
       "      <th>VOLUME_18</th>\n",
       "      <th>RET_19</th>\n",
       "      <th>VOLUME_19</th>\n",
       "      <th>RET_20</th>\n",
       "      <th>VOLUME_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418595.000000</td>\n",
       "      <td>418595.000000</td>\n",
       "      <td>418595.000000</td>\n",
       "      <td>418595.000000</td>\n",
       "      <td>418595.000000</td>\n",
       "      <td>418595.000000</td>\n",
       "      <td>416236.000000</td>\n",
       "      <td>353570.000000</td>\n",
       "      <td>416130.000000</td>\n",
       "      <td>352209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>413315.000000</td>\n",
       "      <td>351333.000000</td>\n",
       "      <td>413294.000000</td>\n",
       "      <td>356281.000000</td>\n",
       "      <td>413288.000000</td>\n",
       "      <td>351009.000000</td>\n",
       "      <td>413282.000000</td>\n",
       "      <td>351266.000000</td>\n",
       "      <td>413254.000000</td>\n",
       "      <td>350738.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>108.659002</td>\n",
       "      <td>3373.567833</td>\n",
       "      <td>37.176020</td>\n",
       "      <td>12.697959</td>\n",
       "      <td>5.483845</td>\n",
       "      <td>90.391663</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>-0.071502</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>-0.075230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>-0.076018</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>-0.087854</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>-0.076147</td>\n",
       "      <td>-0.000798</td>\n",
       "      <td>-0.076496</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.076337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.891642</td>\n",
       "      <td>1533.157749</td>\n",
       "      <td>19.706505</td>\n",
       "      <td>7.231701</td>\n",
       "      <td>2.410113</td>\n",
       "      <td>47.491157</td>\n",
       "      <td>0.031311</td>\n",
       "      <td>3.038658</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>2.635549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029538</td>\n",
       "      <td>2.185741</td>\n",
       "      <td>0.031914</td>\n",
       "      <td>2.094459</td>\n",
       "      <td>0.031435</td>\n",
       "      <td>2.423121</td>\n",
       "      <td>0.030738</td>\n",
       "      <td>2.229668</td>\n",
       "      <td>0.033347</td>\n",
       "      <td>2.721355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.845324</td>\n",
       "      <td>-2.434414</td>\n",
       "      <td>-0.770751</td>\n",
       "      <td>-3.007262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.765478</td>\n",
       "      <td>-5.600056</td>\n",
       "      <td>-0.825014</td>\n",
       "      <td>-4.610393</td>\n",
       "      <td>-0.876157</td>\n",
       "      <td>-4.167784</td>\n",
       "      <td>-0.880000</td>\n",
       "      <td>-2.341887</td>\n",
       "      <td>-0.785714</td>\n",
       "      <td>-2.768928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>-0.010970</td>\n",
       "      <td>-0.555394</td>\n",
       "      <td>-0.011312</td>\n",
       "      <td>-0.540629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>-0.533574</td>\n",
       "      <td>-0.011331</td>\n",
       "      <td>-0.552613</td>\n",
       "      <td>-0.010949</td>\n",
       "      <td>-0.539491</td>\n",
       "      <td>-0.012139</td>\n",
       "      <td>-0.527846</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.542790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>3560.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>-0.282609</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>-0.278437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>-0.272271</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>-0.285480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.281753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.277674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.283405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>4606.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.012950</td>\n",
       "      <td>0.047759</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.029131</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.030201</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.035795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>223.000000</td>\n",
       "      <td>5716.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.444990</td>\n",
       "      <td>1232.174009</td>\n",
       "      <td>1.427746</td>\n",
       "      <td>632.268279</td>\n",
       "      <td>...</td>\n",
       "      <td>1.028902</td>\n",
       "      <td>355.613431</td>\n",
       "      <td>1.707736</td>\n",
       "      <td>408.771698</td>\n",
       "      <td>6.000004</td>\n",
       "      <td>788.461460</td>\n",
       "      <td>2.954430</td>\n",
       "      <td>631.249564</td>\n",
       "      <td>7.208859</td>\n",
       "      <td>932.939205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                DATE          STOCK       INDUSTRY  INDUSTRY_GROUP  \\\n",
       "count  418595.000000  418595.000000  418595.000000   418595.000000   \n",
       "mean      108.659002    3373.567833      37.176020       12.697959   \n",
       "std        61.891642    1533.157749      19.706505        7.231701   \n",
       "min         0.000000       0.000000       0.000000        0.000000   \n",
       "25%        56.000000    2478.000000      22.000000        6.000000   \n",
       "50%       104.000000    3560.000000      43.000000       15.000000   \n",
       "75%       161.000000    4606.000000      53.000000       19.000000   \n",
       "max       223.000000    5716.000000      74.000000       26.000000   \n",
       "\n",
       "              SECTOR   SUB_INDUSTRY          RET_1       VOLUME_1  \\\n",
       "count  418595.000000  418595.000000  416236.000000  353570.000000   \n",
       "mean        5.483845      90.391663       0.001383      -0.071502   \n",
       "std         2.410113      47.491157       0.031311       3.038658   \n",
       "min         0.000000       0.000000      -0.845324      -2.434414   \n",
       "25%         4.000000      49.000000      -0.010970      -0.555394   \n",
       "50%         6.000000     104.000000       0.000637      -0.282609   \n",
       "75%         7.000000     128.000000       0.012950       0.047759   \n",
       "max        11.000000     182.000000       1.444990    1232.174009   \n",
       "\n",
       "               RET_2       VOLUME_2  ...         RET_16      VOLUME_16  \\\n",
       "count  416130.000000  352209.000000  ...  413315.000000  351333.000000   \n",
       "mean        0.000973      -0.075230  ...       0.001074      -0.076018   \n",
       "std         0.030987       2.635549  ...       0.029538       2.185741   \n",
       "min        -0.770751      -3.007262  ...      -0.765478      -5.600056   \n",
       "25%        -0.011312      -0.540629  ...      -0.010527      -0.533574   \n",
       "50%         0.000401      -0.278437  ...       0.000530      -0.272271   \n",
       "75%         0.012326       0.041177  ...       0.012084       0.029131   \n",
       "max         1.427746     632.268279  ...       1.028902     355.613431   \n",
       "\n",
       "              RET_17      VOLUME_17         RET_18      VOLUME_18  \\\n",
       "count  413294.000000  356281.000000  413288.000000  351009.000000   \n",
       "mean        0.001642      -0.087854       0.001131      -0.076147   \n",
       "std         0.031914       2.094459       0.031435       2.423121   \n",
       "min        -0.825014      -4.610393      -0.876157      -4.167784   \n",
       "25%        -0.011331      -0.552613      -0.010949      -0.539491   \n",
       "50%         0.000433      -0.285480       0.000000      -0.281753   \n",
       "75%         0.012862       0.027272       0.012180       0.027639   \n",
       "max         1.707736     408.771698       6.000004     788.461460   \n",
       "\n",
       "              RET_19      VOLUME_19         RET_20      VOLUME_20  \n",
       "count  413282.000000  351266.000000  413254.000000  350738.000000  \n",
       "mean       -0.000798      -0.076496      -0.000027      -0.076337  \n",
       "std         0.030738       2.229668       0.033347       2.721355  \n",
       "min        -0.880000      -2.341887      -0.785714      -2.768928  \n",
       "25%        -0.012139      -0.527846      -0.011682      -0.542790  \n",
       "50%         0.000000      -0.277674       0.000000      -0.283405  \n",
       "75%         0.011236       0.030201       0.011712       0.035795  \n",
       "max         2.954430     631.249564       7.208859     932.939205  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_return = x_train_original[x_train_original.columns[6:16:2]]\n",
    "x_train_volume = x_train_original[x_train_original.columns[7:17:2]]\n",
    "x_test_return = x_test_original[x_test_original.columns[6:16:2]]\n",
    "x_test_volume = x_test_original[x_test_original.columns[7:17:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>VOLUME_2</th>\n",
       "      <th>VOLUME_3</th>\n",
       "      <th>VOLUME_4</th>\n",
       "      <th>VOLUME_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147931</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>0.033832</td>\n",
       "      <td>-0.362868</td>\n",
       "      <td>-0.972920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.096282</td>\n",
       "      <td>0.084771</td>\n",
       "      <td>-0.298777</td>\n",
       "      <td>-0.157421</td>\n",
       "      <td>0.091455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.429540</td>\n",
       "      <td>-0.089919</td>\n",
       "      <td>-0.639737</td>\n",
       "      <td>-0.940163</td>\n",
       "      <td>-0.882464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.847155</td>\n",
       "      <td>-0.943033</td>\n",
       "      <td>-1.180629</td>\n",
       "      <td>-1.313896</td>\n",
       "      <td>-1.204398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418590</th>\n",
       "      <td>-0.217823</td>\n",
       "      <td>-0.125333</td>\n",
       "      <td>-0.674800</td>\n",
       "      <td>-0.150397</td>\n",
       "      <td>-0.026910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418591</th>\n",
       "      <td>-0.375251</td>\n",
       "      <td>-0.029437</td>\n",
       "      <td>3.189102</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>-0.840418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418592</th>\n",
       "      <td>-0.978856</td>\n",
       "      <td>-1.026267</td>\n",
       "      <td>-0.724158</td>\n",
       "      <td>-0.784385</td>\n",
       "      <td>-0.701318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418593</th>\n",
       "      <td>-0.627169</td>\n",
       "      <td>-0.842108</td>\n",
       "      <td>-0.460447</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>-0.039305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418594</th>\n",
       "      <td>-1.325986</td>\n",
       "      <td>0.198856</td>\n",
       "      <td>16.773397</td>\n",
       "      <td>0.598206</td>\n",
       "      <td>10.666016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418595 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VOLUME_1  VOLUME_2   VOLUME_3  VOLUME_4   VOLUME_5\n",
       "ID                                                        \n",
       "0       0.147931  0.179183   0.033832 -0.362868  -0.972920\n",
       "1            NaN       NaN        NaN       NaN        NaN\n",
       "2      -0.096282  0.084771  -0.298777 -0.157421   0.091455\n",
       "3      -0.429540 -0.089919  -0.639737 -0.940163  -0.882464\n",
       "4      -0.847155 -0.943033  -1.180629 -1.313896  -1.204398\n",
       "...          ...       ...        ...       ...        ...\n",
       "418590 -0.217823 -0.125333  -0.674800 -0.150397  -0.026910\n",
       "418591 -0.375251 -0.029437   3.189102  0.403533  -0.840418\n",
       "418592 -0.978856 -1.026267  -0.724158 -0.784385  -0.701318\n",
       "418593 -0.627169 -0.842108  -0.460447  0.040382  -0.039305\n",
       "418594 -1.325986  0.198856  16.773397  0.598206  10.666016\n",
       "\n",
       "[418595 rows x 5 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_return_fillmean = x_train_return.fillna(x_train_return.mean())\n",
    "x_train_volume_fillmean = x_train_volume.fillna(x_train_volume.mean())\n",
    "x_test_return_fillmean = x_test_return.fillna(x_test_return.mean())\n",
    "x_test_volume_fillmean = x_test_volume.fillna(x_test_volume.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61850445, -0.60929181,  0.38969815, -0.57788863,  0.59767037])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_return_np = x_train_return_fillmean.to_numpy()\n",
    "x_train_volume_np = x_train_volume_fillmean.to_numpy()\n",
    "x_test_return_np = x_test_return_fillmean.to_numpy()\n",
    "x_test_volume_np = x_test_volume_fillmean.to_numpy()\n",
    "\n",
    "x_train_return_np = np.clip(x_train_return_np, -0.1, 0.1)\n",
    "x_test_return_np = np.clip(x_test_return_np, -0.1, 0.1)\n",
    "x_train_volume_np = np.clip(x_train_volume_np, -0.1, 0.1)\n",
    "x_test_volume_np = np.clip(x_test_volume_np, -0.1, 0.1)\n",
    "x_train_return_np = (x_train_return_np - x_train_return_np.mean())/(x_train_return_np.std())\n",
    "x_test_return_np = (x_test_return_np - x_train_return_np.mean())/(x_train_return_np.std())\n",
    "x_train_volume_np = (x_train_volume_np - x_train_volume_np.mean())/(x_train_volume_np.std())\n",
    "x_test_volume_np = (x_test_volume_np - x_train_volume_np.mean())/(x_train_volume_np.std())\n",
    "\n",
    "x_train_np = np.concatenate((x_train_return_np, x_train_volume_np, x_train_additional_np), axis=1)\n",
    "x_test_np = np.concatenate((x_test_return_np, x_test_volume_np, x_test_additional_np), axis=1)\n",
    "x_train_return_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_train_volume_hist = einops.rearrange(x_train_return_np, \" a b -> (a b)\")\n",
    "\n",
    "plt.hist(x_train_volume_hist, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.61850445, -0.60929181,  0.38969815, -0.57788863,  0.59767037],\n",
       "       [ 0.12604177, -3.44212248,  0.68607681, -0.98797331, -1.46048059],\n",
       "       [-0.00766971, -2.24658847, -0.3654797 ,  0.91345878,  0.32865147],\n",
       "       ...,\n",
       "       [ 0.80089718, -0.24800063,  0.39033643,  0.20324436, -0.62143363],\n",
       "       [ 0.43785899,  0.38793223,  0.28045117,  0.53805875,  0.23046555],\n",
       "       [ 2.8495127 , -0.06157142,  2.22781538,  1.03173804,  0.34482878]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_return_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"Data/y_train.csv\")\n",
    "y_train_np = y_train.to_numpy()[:,1]\n",
    "#print(y_train_np)\n",
    "y_train_mapped_np = np.array([1 if val else 0 for val in y_train_np])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          True\n",
      "1          True\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "418590    False\n",
      "418591    False\n",
      "418592     True\n",
      "418593     True\n",
      "418594    False\n",
      "Name: RET, Length: 418595, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"Data/y_train.csv\")\n",
    "print(test[test.columns[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train_np).float()\n",
    "x_test = torch.tensor(x_test_np).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "y_train = torch.tensor(y_train_mapped_np).long()\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49.8921)\n",
      "50.10786056518555\n"
     ]
    }
   ],
   "source": [
    "percentage_1 = y_train.eq(1).float().mean()*100\n",
    "print(percentage_1)\n",
    "print(100-percentage_1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 640\n",
    "train_ds = TensorDataset(x_train,y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_dl = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Date 223\n",
    "        # Industry 74\n",
    "        # Industry_group 26\n",
    "        # Sector 11\n",
    "        # Sub_industry 182\n",
    "\n",
    "        # feature dimension - 12, 8, 6, 4, 12\n",
    "        '''\n",
    "        self.stock_encodings = nn.Parameter(torch.rand(5717, 16, requires_grad=True))\n",
    "        self.industry_encodings = nn.Parameter(torch.rand(75, 8, requires_grad=True))\n",
    "        self.industry_group_encodings = nn.Parameter(torch.rand(27, 6, requires_grad=True))\n",
    "        self.sector_encodings = nn.Parameter(torch.rand(12, 4, requires_grad=True))\n",
    "        self.sub_industry_encodings = nn.Parameter(torch.rand(183, 12, requires_grad=True))\n",
    "        '''\n",
    "        self.date_encodings = nn.Embedding(224,8)\n",
    "        self.industry_encodings = nn.Embedding(75,4)\n",
    "        self.industry_group_encodings = nn.Embedding(27,4)\n",
    "        self.sector_encodings = nn.Embedding(12,3)\n",
    "        self.sub_industry_encodings = nn.Embedding(183,8)\n",
    "\n",
    "    def forward(self,input):\n",
    "        #print(input)\n",
    "        date_encoding = self.date_encodings(input[:,0].long())\n",
    "        industry_encoding = self.industry_encodings(input[:,1].long())\n",
    "        industry_group_encoding = self.industry_group_encodings(input[:,2].long())\n",
    "        sector_encoding = self.sector_encodings(input[:,3].long())\n",
    "        sub_industry_encoding = self.sub_industry_encodings(input[:,4].long())\n",
    "        return torch.cat((date_encoding,industry_encoding,industry_group_encoding,sector_encoding,sub_industry_encoding), dim=1)\n",
    "\n",
    "\n",
    "class DenseNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding = Embedding()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        #print(\"input[-5:]\", input[:,-5:].long())\n",
    "        embedding = self.embedding(input[:,-5:].long())\n",
    "        full_vec = torch.cat((input[:,:-5],embedding), dim=1)\n",
    "        output = self.layers(full_vec)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNetwork(37)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.6627904176712036, acc: 59.84375\n",
      "epoch: 0, loss: 0.6616555452346802, acc: 59.84375\n",
      "epoch: 0, loss: 0.6519640684127808, acc: 61.874996185302734\n",
      "epoch: 0, loss: 0.6693950891494751, acc: 58.59375\n",
      "epoch: 0, loss: 0.6606839299201965, acc: 60.9375\n",
      "epoch: 0, loss: 0.6653046607971191, acc: 56.71875\n",
      "epoch: 0, loss: 0.659122109413147, acc: 58.28125\n",
      "epoch: 0, loss: 0.673193097114563, acc: 59.531246185302734\n",
      "epoch: 0, loss: 0.6689351797103882, acc: 59.6875\n",
      "epoch: 0, loss: 0.6569609045982361, acc: 62.1875\n",
      "epoch: 0, loss: 0.6715775728225708, acc: 56.093753814697266\n",
      "epoch: 0, loss: 0.6916635036468506, acc: 54.843746185302734\n",
      "epoch: 0, loss: 0.6586211919784546, acc: 60.46875\n",
      "epoch: 0, loss: 0.6779392957687378, acc: 55.46875\n",
      "epoch: 0, loss: 0.671282172203064, acc: 57.03125\n",
      "epoch: 0, loss: 0.6636433005332947, acc: 60.15625\n",
      "epoch: 0, loss: 0.6741583943367004, acc: 57.8125\n",
      "epoch: 0, loss: 0.6745782494544983, acc: 58.437503814697266\n",
      "epoch: 0, loss: 0.662056565284729, acc: 58.28125\n",
      "epoch: 0, loss: 0.6687323451042175, acc: 57.03125\n",
      "epoch: 0, loss: 0.6684378385543823, acc: 57.5\n",
      "epoch: 0, loss: 0.663143515586853, acc: 59.6875\n",
      "epoch: 0, loss: 0.6831712126731873, acc: 57.187496185302734\n",
      "epoch: 0, loss: 0.6691714525222778, acc: 57.03125\n",
      "epoch: 0, loss: 0.6773388981819153, acc: 53.59375\n",
      "epoch: 0, loss: 0.6546961069107056, acc: 61.562503814697266\n",
      "epoch: 0, loss: 0.6802967190742493, acc: 57.8125\n",
      "epoch: 0, loss: 0.6633372902870178, acc: 58.90625\n",
      "epoch: 0, loss: 0.6776574850082397, acc: 57.5\n",
      "epoch: 0, loss: 0.6804227828979492, acc: 56.406246185302734\n",
      "epoch: 0, loss: 0.6742576360702515, acc: 58.28125\n",
      "epoch: 0, loss: 0.6702989339828491, acc: 55.0\n",
      "epoch: 0, loss: 0.6722968220710754, acc: 56.093753814697266\n",
      "epoch: 0, loss: 0.6873906254768372, acc: 54.375\n",
      "epoch: 0, loss: 0.6745595932006836, acc: 57.8125\n",
      "epoch: 0, loss: 0.6713731288909912, acc: 58.437503814697266\n",
      "epoch: 0, loss: 0.6765328645706177, acc: 56.25\n",
      "epoch: 0, loss: 0.6767400503158569, acc: 56.25\n",
      "epoch: 0, loss: 0.663779616355896, acc: 57.187496185302734\n",
      "epoch: 0, loss: 0.6758843660354614, acc: 58.749996185302734\n",
      "epoch: 0, loss: 0.664490818977356, acc: 59.84375\n",
      "epoch: 0, loss: 0.668002188205719, acc: 57.03125\n",
      "epoch: 0, loss: 0.668181300163269, acc: 59.531246185302734\n",
      "epoch: 0, loss: 0.6695258617401123, acc: 58.90625\n",
      "epoch: 0, loss: 0.6637082099914551, acc: 58.437503814697266\n",
      "epoch: 0, loss: 0.6551182270050049, acc: 60.625\n",
      "epoch: 0, loss: 0.6645336747169495, acc: 59.375\n",
      "epoch: 0, loss: 0.6573034524917603, acc: 59.84375\n",
      "epoch: 0, loss: 0.6701961159706116, acc: 58.749996185302734\n",
      "epoch: 0, loss: 0.673937976360321, acc: 56.093753814697266\n",
      "epoch: 0, loss: 0.6561675071716309, acc: 60.781253814697266\n",
      "epoch: 0, loss: 0.6626293659210205, acc: 60.46875\n",
      "epoch: 0, loss: 0.6695022583007812, acc: 58.28125\n",
      "epoch: 0, loss: 0.6660742163658142, acc: 59.0625\n",
      "epoch: 0, loss: 0.6546002626419067, acc: 60.15625\n",
      "epoch: 0, loss: 0.6579538583755493, acc: 60.781253814697266\n",
      "epoch: 0, loss: 0.6672805547714233, acc: 58.749996185302734\n",
      "epoch: 0, loss: 0.6636874675750732, acc: 59.218753814697266\n",
      "epoch: 0, loss: 0.6654610633850098, acc: 58.125\n",
      "epoch: 0, loss: 0.674018383026123, acc: 56.875003814697266\n",
      "epoch: 0, loss: 0.6658200621604919, acc: 58.59375\n",
      "epoch: 0, loss: 0.6539320945739746, acc: 62.03125\n",
      "epoch: 0, loss: 0.6673951148986816, acc: 57.968746185302734\n",
      "epoch: 0, loss: 0.6670732498168945, acc: 55.78125\n",
      "epoch: 0, loss: 0.6627508401870728, acc: 58.59375\n",
      "epoch: 0, loss: 0.6826105117797852, acc: 55.312503814697266\n",
      "Epoch: 0, average accuracy: 58.297914362317734\n",
      "epoch: 1, loss: 0.6710036396980286, acc: 58.437503814697266\n",
      "epoch: 1, loss: 0.6662739515304565, acc: 57.8125\n",
      "epoch: 1, loss: 0.6715195775032043, acc: 58.125\n",
      "epoch: 1, loss: 0.6550217866897583, acc: 60.9375\n",
      "epoch: 1, loss: 0.6681524515151978, acc: 56.875003814697266\n",
      "epoch: 1, loss: 0.6792327761650085, acc: 55.15625\n",
      "epoch: 1, loss: 0.6626948714256287, acc: 59.6875\n",
      "epoch: 1, loss: 0.6761597394943237, acc: 53.90625\n",
      "epoch: 1, loss: 0.6635544896125793, acc: 59.6875\n",
      "epoch: 1, loss: 0.6679051518440247, acc: 58.90625\n",
      "epoch: 1, loss: 0.6612228751182556, acc: 59.375\n",
      "epoch: 1, loss: 0.6585832834243774, acc: 59.375\n",
      "epoch: 1, loss: 0.6721219420433044, acc: 59.218753814697266\n",
      "epoch: 1, loss: 0.6595019698143005, acc: 59.531246185302734\n",
      "epoch: 1, loss: 0.6753661632537842, acc: 57.5\n",
      "epoch: 1, loss: 0.6744012832641602, acc: 57.187496185302734\n",
      "epoch: 1, loss: 0.6734367609024048, acc: 54.375\n",
      "epoch: 1, loss: 0.650970995426178, acc: 62.8125\n",
      "epoch: 1, loss: 0.6491670608520508, acc: 62.96875\n",
      "epoch: 1, loss: 0.6677024364471436, acc: 58.59375\n",
      "epoch: 1, loss: 0.6580899357795715, acc: 58.90625\n",
      "epoch: 1, loss: 0.6570004820823669, acc: 60.312496185302734\n",
      "epoch: 1, loss: 0.6796619296073914, acc: 55.15625\n",
      "epoch: 1, loss: 0.6680150628089905, acc: 59.218753814697266\n",
      "epoch: 1, loss: 0.6670854687690735, acc: 57.34375\n",
      "epoch: 1, loss: 0.6738669276237488, acc: 57.5\n",
      "epoch: 1, loss: 0.6716911792755127, acc: 56.5625\n",
      "epoch: 1, loss: 0.6653189659118652, acc: 58.749996185302734\n",
      "epoch: 1, loss: 0.6697365045547485, acc: 57.968746185302734\n",
      "epoch: 1, loss: 0.6651344299316406, acc: 57.968746185302734\n",
      "epoch: 1, loss: 0.6712098717689514, acc: 58.90625\n",
      "epoch: 1, loss: 0.6651694178581238, acc: 58.125\n",
      "epoch: 1, loss: 0.6642279624938965, acc: 59.531246185302734\n",
      "epoch: 1, loss: 0.6642736196517944, acc: 60.000003814697266\n",
      "epoch: 1, loss: 0.6713132858276367, acc: 57.656253814697266\n",
      "epoch: 1, loss: 0.6582803130149841, acc: 60.625\n",
      "epoch: 1, loss: 0.6562218070030212, acc: 59.0625\n",
      "epoch: 1, loss: 0.6665671467781067, acc: 60.15625\n",
      "epoch: 1, loss: 0.6603790521621704, acc: 59.375\n",
      "epoch: 1, loss: 0.6616698503494263, acc: 59.375\n",
      "epoch: 1, loss: 0.6646928191184998, acc: 54.531253814697266\n",
      "epoch: 1, loss: 0.681965172290802, acc: 55.46875\n",
      "epoch: 1, loss: 0.6644289493560791, acc: 57.187496185302734\n",
      "epoch: 1, loss: 0.6690716743469238, acc: 56.875003814697266\n",
      "epoch: 1, loss: 0.6748289465904236, acc: 55.624996185302734\n",
      "epoch: 1, loss: 0.6521263122558594, acc: 60.312496185302734\n",
      "epoch: 1, loss: 0.669785737991333, acc: 57.34375\n",
      "epoch: 1, loss: 0.6503360271453857, acc: 63.28125\n",
      "epoch: 1, loss: 0.6580466032028198, acc: 60.312496185302734\n",
      "epoch: 1, loss: 0.669293224811554, acc: 57.968746185302734\n",
      "epoch: 1, loss: 0.6646304130554199, acc: 57.968746185302734\n",
      "epoch: 1, loss: 0.6716697216033936, acc: 57.8125\n",
      "epoch: 1, loss: 0.6596019864082336, acc: 60.781253814697266\n",
      "epoch: 1, loss: 0.679876983165741, acc: 54.21875\n",
      "epoch: 1, loss: 0.6550304293632507, acc: 63.28125\n",
      "epoch: 1, loss: 0.6878496408462524, acc: 55.9375\n",
      "epoch: 1, loss: 0.651944100856781, acc: 60.000003814697266\n",
      "epoch: 1, loss: 0.6961377263069153, acc: 51.5625\n",
      "epoch: 1, loss: 0.6652398109436035, acc: 57.5\n",
      "epoch: 1, loss: 0.6679803133010864, acc: 58.749996185302734\n",
      "epoch: 1, loss: 0.671671986579895, acc: 57.03125\n",
      "epoch: 1, loss: 0.6618906855583191, acc: 62.1875\n",
      "epoch: 1, loss: 0.6642993688583374, acc: 55.9375\n",
      "epoch: 1, loss: 0.6738092303276062, acc: 58.59375\n",
      "epoch: 1, loss: 0.6701515316963196, acc: 57.187496185302734\n",
      "epoch: 1, loss: 0.6630903482437134, acc: 57.968746185302734\n",
      "Epoch: 1, average accuracy: 58.52146945400092\n",
      "epoch: 2, loss: 0.6663265824317932, acc: 56.406246185302734\n",
      "epoch: 2, loss: 0.6514739990234375, acc: 59.531246185302734\n",
      "epoch: 2, loss: 0.6778895258903503, acc: 60.15625\n",
      "epoch: 2, loss: 0.6653763651847839, acc: 59.531246185302734\n",
      "epoch: 2, loss: 0.6705328226089478, acc: 58.28125\n",
      "epoch: 2, loss: 0.6648872494697571, acc: 59.375\n",
      "epoch: 2, loss: 0.6602141261100769, acc: 60.46875\n",
      "epoch: 2, loss: 0.6756922006607056, acc: 56.25\n",
      "epoch: 2, loss: 0.6680455803871155, acc: 55.78125\n",
      "epoch: 2, loss: 0.674359917640686, acc: 56.71875\n",
      "epoch: 2, loss: 0.6612532734870911, acc: 59.0625\n",
      "epoch: 2, loss: 0.6660963892936707, acc: 58.125\n",
      "epoch: 2, loss: 0.6714590787887573, acc: 58.59375\n",
      "epoch: 2, loss: 0.6732865571975708, acc: 57.968746185302734\n",
      "epoch: 2, loss: 0.6581965684890747, acc: 61.25\n",
      "epoch: 2, loss: 0.6732317209243774, acc: 57.34375\n",
      "epoch: 2, loss: 0.656499981880188, acc: 59.218753814697266\n",
      "epoch: 2, loss: 0.6710447072982788, acc: 57.8125\n",
      "epoch: 2, loss: 0.6671465039253235, acc: 57.03125\n",
      "epoch: 2, loss: 0.6688849925994873, acc: 58.59375\n",
      "epoch: 2, loss: 0.6649121046066284, acc: 60.000003814697266\n",
      "epoch: 2, loss: 0.6552773714065552, acc: 60.15625\n",
      "epoch: 2, loss: 0.6744439005851746, acc: 59.6875\n",
      "epoch: 2, loss: 0.64920574426651, acc: 61.25\n",
      "epoch: 2, loss: 0.6563016772270203, acc: 58.28125\n",
      "epoch: 2, loss: 0.6604917645454407, acc: 62.1875\n",
      "epoch: 2, loss: 0.6552672386169434, acc: 61.874996185302734\n",
      "epoch: 2, loss: 0.6676801443099976, acc: 55.46875\n",
      "epoch: 2, loss: 0.6611219048500061, acc: 60.46875\n",
      "epoch: 2, loss: 0.6542582511901855, acc: 60.15625\n",
      "epoch: 2, loss: 0.6718547344207764, acc: 57.8125\n",
      "epoch: 2, loss: 0.6700888872146606, acc: 56.71875\n",
      "epoch: 2, loss: 0.679951548576355, acc: 55.46875\n",
      "epoch: 2, loss: 0.6563846468925476, acc: 60.312496185302734\n",
      "epoch: 2, loss: 0.668701171875, acc: 60.312496185302734\n",
      "epoch: 2, loss: 0.6656706929206848, acc: 58.749996185302734\n",
      "epoch: 2, loss: 0.661095380783081, acc: 59.84375\n",
      "epoch: 2, loss: 0.6572968363761902, acc: 60.46875\n",
      "epoch: 2, loss: 0.6705000996589661, acc: 58.59375\n",
      "epoch: 2, loss: 0.6639474034309387, acc: 58.28125\n",
      "epoch: 2, loss: 0.6615106463432312, acc: 59.84375\n",
      "epoch: 2, loss: 0.6597369909286499, acc: 60.46875\n",
      "epoch: 2, loss: 0.6766196489334106, acc: 57.03125\n",
      "epoch: 2, loss: 0.6529561877250671, acc: 61.71875\n",
      "epoch: 2, loss: 0.6418954730033875, acc: 62.8125\n",
      "epoch: 2, loss: 0.6528103351593018, acc: 61.40625\n",
      "epoch: 2, loss: 0.6591749787330627, acc: 55.46875\n",
      "epoch: 2, loss: 0.6628340482711792, acc: 58.28125\n",
      "epoch: 2, loss: 0.6660322546958923, acc: 57.34375\n",
      "epoch: 2, loss: 0.6532924175262451, acc: 59.531246185302734\n",
      "epoch: 2, loss: 0.6648150682449341, acc: 57.968746185302734\n",
      "epoch: 2, loss: 0.6528182029724121, acc: 59.218753814697266\n",
      "epoch: 2, loss: 0.6649242639541626, acc: 59.531246185302734\n",
      "epoch: 2, loss: 0.6603687405586243, acc: 59.375\n",
      "epoch: 2, loss: 0.67192542552948, acc: 57.968746185302734\n",
      "epoch: 2, loss: 0.6871916651725769, acc: 57.34375\n",
      "epoch: 2, loss: 0.6650422811508179, acc: 57.656253814697266\n",
      "epoch: 2, loss: 0.6597153544425964, acc: 59.375\n",
      "epoch: 2, loss: 0.6628206968307495, acc: 58.59375\n",
      "epoch: 2, loss: 0.672683835029602, acc: 57.8125\n",
      "epoch: 2, loss: 0.6750026345252991, acc: 57.8125\n",
      "epoch: 2, loss: 0.6685530543327332, acc: 57.968746185302734\n",
      "epoch: 2, loss: 0.6569751501083374, acc: 60.312496185302734\n",
      "epoch: 2, loss: 0.6617381572723389, acc: 57.656253814697266\n",
      "epoch: 2, loss: 0.658856987953186, acc: 58.28125\n",
      "epoch: 2, loss: 0.6577430963516235, acc: 60.625\n",
      "Epoch: 2, average accuracy: 58.73640263681193\n",
      "epoch: 3, loss: 0.664993166923523, acc: 60.781253814697266\n",
      "epoch: 3, loss: 0.653412938117981, acc: 61.093746185302734\n",
      "epoch: 3, loss: 0.6726400852203369, acc: 58.28125\n",
      "epoch: 3, loss: 0.6588895916938782, acc: 60.312496185302734\n",
      "epoch: 3, loss: 0.6659581661224365, acc: 59.218753814697266\n",
      "epoch: 3, loss: 0.6604305505752563, acc: 59.218753814697266\n",
      "epoch: 3, loss: 0.655448317527771, acc: 60.625\n",
      "epoch: 3, loss: 0.662280797958374, acc: 57.34375\n",
      "epoch: 3, loss: 0.6690201163291931, acc: 56.71875\n",
      "epoch: 3, loss: 0.663234293460846, acc: 58.749996185302734\n",
      "epoch: 3, loss: 0.6636476516723633, acc: 60.9375\n",
      "epoch: 3, loss: 0.6563223600387573, acc: 59.84375\n",
      "epoch: 3, loss: 0.642632246017456, acc: 63.75\n",
      "epoch: 3, loss: 0.6686426401138306, acc: 56.093753814697266\n",
      "epoch: 3, loss: 0.6645730137825012, acc: 59.84375\n",
      "epoch: 3, loss: 0.6710913181304932, acc: 56.406246185302734\n",
      "epoch: 3, loss: 0.6615992784500122, acc: 58.28125\n",
      "epoch: 3, loss: 0.6816964745521545, acc: 58.749996185302734\n",
      "epoch: 3, loss: 0.673632025718689, acc: 60.625\n",
      "epoch: 3, loss: 0.6596810817718506, acc: 61.093746185302734\n",
      "epoch: 3, loss: 0.6668558716773987, acc: 58.437503814697266\n",
      "epoch: 3, loss: 0.6463121175765991, acc: 60.15625\n",
      "epoch: 3, loss: 0.6532397270202637, acc: 62.343753814697266\n",
      "epoch: 3, loss: 0.6587499380111694, acc: 61.25\n",
      "epoch: 3, loss: 0.6800685524940491, acc: 58.59375\n",
      "epoch: 3, loss: 0.6516096591949463, acc: 60.15625\n",
      "epoch: 3, loss: 0.6674295663833618, acc: 59.531246185302734\n",
      "epoch: 3, loss: 0.6602655649185181, acc: 58.90625\n",
      "epoch: 3, loss: 0.6391860842704773, acc: 62.1875\n",
      "epoch: 3, loss: 0.6641637682914734, acc: 57.8125\n",
      "epoch: 3, loss: 0.6754524111747742, acc: 58.125\n",
      "epoch: 3, loss: 0.6642016172409058, acc: 59.218753814697266\n",
      "epoch: 3, loss: 0.6713912487030029, acc: 57.656253814697266\n",
      "epoch: 3, loss: 0.6710699796676636, acc: 58.59375\n",
      "epoch: 3, loss: 0.6595351099967957, acc: 59.0625\n",
      "epoch: 3, loss: 0.6600971817970276, acc: 58.749996185302734\n",
      "epoch: 3, loss: 0.6601452231407166, acc: 60.625\n",
      "epoch: 3, loss: 0.672620952129364, acc: 58.749996185302734\n",
      "epoch: 3, loss: 0.6623638868331909, acc: 59.218753814697266\n",
      "epoch: 3, loss: 0.6710257530212402, acc: 58.90625\n",
      "epoch: 3, loss: 0.6557753682136536, acc: 59.531246185302734\n",
      "epoch: 3, loss: 0.6684255003929138, acc: 60.312496185302734\n",
      "epoch: 3, loss: 0.6718918085098267, acc: 58.90625\n",
      "epoch: 3, loss: 0.6760138273239136, acc: 54.6875\n",
      "epoch: 3, loss: 0.6730695366859436, acc: 56.875003814697266\n",
      "epoch: 3, loss: 0.6699255704879761, acc: 59.218753814697266\n",
      "epoch: 3, loss: 0.6585863828659058, acc: 62.96875\n",
      "epoch: 3, loss: 0.6601688861846924, acc: 60.000003814697266\n",
      "epoch: 3, loss: 0.6777194738388062, acc: 55.9375\n",
      "epoch: 3, loss: 0.6592634320259094, acc: 58.437503814697266\n",
      "epoch: 3, loss: 0.6599959135055542, acc: 60.15625\n",
      "epoch: 3, loss: 0.6668360829353333, acc: 58.749996185302734\n",
      "epoch: 3, loss: 0.6702690124511719, acc: 59.0625\n",
      "epoch: 3, loss: 0.6651920080184937, acc: 60.9375\n",
      "epoch: 3, loss: 0.6457786560058594, acc: 60.781253814697266\n",
      "epoch: 3, loss: 0.6576597690582275, acc: 60.312496185302734\n",
      "epoch: 3, loss: 0.6736048460006714, acc: 57.968746185302734\n",
      "epoch: 3, loss: 0.6622281074523926, acc: 60.000003814697266\n",
      "epoch: 3, loss: 0.6571812033653259, acc: 58.59375\n",
      "epoch: 3, loss: 0.6712818741798401, acc: 57.34375\n",
      "epoch: 3, loss: 0.6660533547401428, acc: 58.90625\n",
      "epoch: 3, loss: 0.6406195759773254, acc: 62.343753814697266\n",
      "epoch: 3, loss: 0.6706165671348572, acc: 60.15625\n",
      "epoch: 3, loss: 0.6510838270187378, acc: 59.218753814697266\n",
      "epoch: 3, loss: 0.6385905146598816, acc: 63.125003814697266\n",
      "epoch: 3, loss: 0.6654530763626099, acc: 60.312496185302734\n",
      "Epoch: 3, average accuracy: 59.022628277494704\n",
      "epoch: 4, loss: 0.6660213470458984, acc: 59.218753814697266\n",
      "epoch: 4, loss: 0.6638482213020325, acc: 59.531246185302734\n",
      "epoch: 4, loss: 0.6669775247573853, acc: 58.125\n",
      "epoch: 4, loss: 0.664208710193634, acc: 59.218753814697266\n",
      "epoch: 4, loss: 0.6527491807937622, acc: 61.874996185302734\n",
      "epoch: 4, loss: 0.6611548662185669, acc: 59.375\n",
      "epoch: 4, loss: 0.6892215013504028, acc: 55.312503814697266\n",
      "epoch: 4, loss: 0.6768559217453003, acc: 57.8125\n",
      "epoch: 4, loss: 0.6547371745109558, acc: 60.15625\n",
      "epoch: 4, loss: 0.6615860462188721, acc: 59.531246185302734\n",
      "epoch: 4, loss: 0.6627256870269775, acc: 58.59375\n",
      "epoch: 4, loss: 0.652231752872467, acc: 61.25\n",
      "epoch: 4, loss: 0.6582154035568237, acc: 58.59375\n",
      "epoch: 4, loss: 0.6600373983383179, acc: 60.46875\n",
      "epoch: 4, loss: 0.6494265794754028, acc: 59.84375\n",
      "epoch: 4, loss: 0.6507157683372498, acc: 62.5\n",
      "epoch: 4, loss: 0.6757806539535522, acc: 55.15625\n",
      "epoch: 4, loss: 0.6693819761276245, acc: 59.6875\n",
      "epoch: 4, loss: 0.6665347218513489, acc: 58.59375\n",
      "epoch: 4, loss: 0.6653225421905518, acc: 58.90625\n",
      "epoch: 4, loss: 0.6511393785476685, acc: 59.531246185302734\n",
      "epoch: 4, loss: 0.6641212701797485, acc: 62.343753814697266\n",
      "epoch: 4, loss: 0.6682571172714233, acc: 59.375\n",
      "epoch: 4, loss: 0.6507136225700378, acc: 62.8125\n",
      "epoch: 4, loss: 0.6624439358711243, acc: 61.40625\n",
      "epoch: 4, loss: 0.6520901918411255, acc: 60.000003814697266\n",
      "epoch: 4, loss: 0.6549234986305237, acc: 63.28125\n",
      "epoch: 4, loss: 0.6587511301040649, acc: 57.8125\n",
      "epoch: 4, loss: 0.6508733034133911, acc: 60.625\n",
      "epoch: 4, loss: 0.6651032567024231, acc: 59.375\n",
      "epoch: 4, loss: 0.6736987829208374, acc: 60.625\n",
      "epoch: 4, loss: 0.6694296598434448, acc: 58.125\n",
      "epoch: 4, loss: 0.6563903093338013, acc: 61.874996185302734\n",
      "epoch: 4, loss: 0.674358069896698, acc: 56.406246185302734\n",
      "epoch: 4, loss: 0.6739565134048462, acc: 57.34375\n",
      "epoch: 4, loss: 0.6770874261856079, acc: 56.5625\n",
      "epoch: 4, loss: 0.6654515862464905, acc: 59.218753814697266\n",
      "epoch: 4, loss: 0.6508957147598267, acc: 62.8125\n",
      "epoch: 4, loss: 0.6592555046081543, acc: 60.781253814697266\n",
      "epoch: 4, loss: 0.6604080200195312, acc: 60.46875\n",
      "epoch: 4, loss: 0.6652446985244751, acc: 59.0625\n",
      "epoch: 4, loss: 0.6737789511680603, acc: 56.875003814697266\n",
      "epoch: 4, loss: 0.6619435548782349, acc: 58.437503814697266\n",
      "epoch: 4, loss: 0.6549841165542603, acc: 59.375\n",
      "epoch: 4, loss: 0.6484113931655884, acc: 61.40625\n",
      "epoch: 4, loss: 0.6430081725120544, acc: 62.8125\n",
      "epoch: 4, loss: 0.6523224115371704, acc: 60.46875\n",
      "epoch: 4, loss: 0.6630474328994751, acc: 55.9375\n",
      "epoch: 4, loss: 0.6736981868743896, acc: 57.03125\n",
      "epoch: 4, loss: 0.6605173945426941, acc: 58.90625\n",
      "epoch: 4, loss: 0.6675771474838257, acc: 58.437503814697266\n",
      "epoch: 4, loss: 0.6625950336456299, acc: 59.6875\n",
      "epoch: 4, loss: 0.665781557559967, acc: 58.749996185302734\n",
      "epoch: 4, loss: 0.6693922281265259, acc: 58.28125\n",
      "epoch: 4, loss: 0.658210039138794, acc: 59.6875\n",
      "epoch: 4, loss: 0.68498694896698, acc: 55.46875\n",
      "epoch: 4, loss: 0.6690011024475098, acc: 58.125\n",
      "epoch: 4, loss: 0.6699994802474976, acc: 60.9375\n",
      "epoch: 4, loss: 0.6701083183288574, acc: 57.03125\n",
      "epoch: 4, loss: 0.6602975726127625, acc: 60.15625\n",
      "epoch: 4, loss: 0.6816056966781616, acc: 57.187496185302734\n",
      "epoch: 4, loss: 0.6519964933395386, acc: 62.656246185302734\n",
      "epoch: 4, loss: 0.6921055912971497, acc: 55.312503814697266\n",
      "epoch: 4, loss: 0.6859269142150879, acc: 56.093753814697266\n",
      "epoch: 4, loss: 0.6544523239135742, acc: 60.312496185302734\n",
      "epoch: 4, loss: 0.6762858033180237, acc: 56.406246185302734\n",
      "Epoch: 4, average accuracy: 59.0645446893823\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "epoch = 0\n",
    "\n",
    "while epoch < epochs:\n",
    "    accuracies = []\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        data, label = batch\n",
    "        #print(\"data\", data.size())\n",
    "        #print(\"label\", label.size())\n",
    "        output = model(data)\n",
    "        #print(\"output\", output.size())\n",
    "        loss = criterion(output, label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        argmax = torch.argmax(output, dim=1)\n",
    "        accuracy = argmax.eq(label).float().mean()*100\n",
    "        accuracies.append(accuracy.item())\n",
    "        \n",
    "        if i*batch_size % 6400 == 0:\n",
    "            print(f\"epoch: {epoch}, loss: {loss}, acc: {accuracy}\")\n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, average accuracy: {statistics.mean(accuracies)}\")\n",
    "    epoch += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_argmax = torch.argmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 1, 1, 1])\n",
      "            0\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n",
      "...       ...\n",
      "198424  False\n",
      "198425   True\n",
      "198426   True\n",
      "198427   True\n",
      "198428   True\n",
      "\n",
      "[198429 rows x 1 columns]\n",
      "Int64Index([418595, 418596, 418597, 418598, 418599, 418600, 418601, 418602,\n",
      "            418603, 418604,\n",
      "            ...\n",
      "            617014, 617015, 617016, 617017, 617018, 617019, 617020, 617021,\n",
      "            617022, 617023],\n",
      "           dtype='int64', name='ID', length=198429)\n"
     ]
    }
   ],
   "source": [
    "print(output_argmax)\n",
    "output_tf = [True if val == 1 else False for val in output_argmax]\n",
    "#print(output_tf)\n",
    "output_df = pd.DataFrame(output_tf)\n",
    "print(output_df)\n",
    "output_df = output_df.squeeze()\n",
    "output_df.index = x_test_original.index\n",
    "output_df.name = 'RET'\n",
    "print(x_test_original.index)\n",
    "submission = pd.Series(output_tf)\n",
    "submission.index = x_test_original.index\n",
    "submission.name = \"RET\"\n",
    "submission.to_csv(\"output.csv\", index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"best.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64907145c6e514ce78e4676ca34bdc24480dd4ed0db374ceb884ad79dda0cf9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
